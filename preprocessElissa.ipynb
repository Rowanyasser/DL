{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import nltk and download required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nltk\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('punkt')  \n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 2.17.0\n",
      "Keras Version: 3.6.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "print(\"TensorFlow Version:\", tf.__version__)\n",
    "print(\"Keras Version:\", keras.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Necessary Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer, ISRIStemmer\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from transformers import pipeline\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "arabic_stopwords = set(stopwords.words('arabic'))\n",
    "arabic_stopwords\n",
    "stemmer = ISRIStemmer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Lyrics Sample:\n",
      "0    متخفش مني\\nمتخفش مني\\nمتخفش مني\\nمتخفش مني\\nأن...\n",
      "1    أجمل إحساس\\nأجمل إحساس\\nأجمل إحساس\\nأجمل إحساس...\n",
      "2    أسعد واحدة\\nأسعد واحدة\\nأسعد واحدة\\nالفرحة الل...\n",
      "3    أغلى الحبايب\\nأغلى الحبايب\\nأغلى الحبايب\\nأغلى...\n",
      "4    أنا بستغرب عليه\\nأنا بستغرب عليه\\nأنا بستغرب ع...\n",
      "Name: Lyrics, dtype: object\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('C:\\\\Users\\\\Kimo Store\\\\Downloads\\\\deep\\\\output\\\\elissa_lyrics.csv', encoding='utf-8-sig')\n",
    "print(\"Original Lyrics Sample:\")\n",
    "print(df['Lyrics'].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions used for preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_diacritics(text):\n",
    "    diacritics = r'[\\u0617-\\u061A\\u064B-\\u065F]'\n",
    "    text = re.sub(diacritics, '', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_hamzas(text):\n",
    "    text = re.sub(r'[أإآٱ]', 'ا', text)  # أ, إ, آ, ٱ → ا\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replaced_words(text):\n",
    "    text= re.sub(r'ة', 'ه', text) #ة → ه\n",
    "    text = re.sub(r'ي\\b', 'ى', text) #ي → ى\n",
    "    return text   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove repeated letters\n",
    "def deduplicate_letters(text):\n",
    "    return re.sub(r'(.)\\1+', r'\\1', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_text(text):\n",
    "    text = remove_diacritics(text)\n",
    "    text = remove_hamzas(text)\n",
    "    text = replaced_words(text)\n",
    "    text = deduplicate_letters(text)\n",
    "    text = remove_punctuation(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    words = text.split()\n",
    "    filtered_words = [word for word in words if word not in arabic_stopwords]\n",
    "    return ' '.join(filtered_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_text(text):\n",
    "    return [word for word in text.split() if word.strip()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "arabic_stopwords_normalized = {normalize_text(word) for word in arabic_stopwords}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    \n",
    "    # Remove diacritics\n",
    "    text = remove_diacritics(text)\n",
    "    \n",
    "    # Normalize Arabic letters\n",
    "    text = remove_hamzas(text)\n",
    "    text = replaced_words(text)\n",
    "    \n",
    "    # Remove repeated letters\n",
    "    text = deduplicate_letters(text)\n",
    "    \n",
    "    # Remove punctuation\n",
    "    text = remove_punctuation(text)\n",
    "    \n",
    "    # Tokenize ensuring strict separation of words\n",
    "    tokens = re.findall(r'\\b\\w+\\b', text)  # Extract words strictly\n",
    "    \n",
    "    # Remove stopwords\n",
    "    tokens = [word for word in tokens if word not in arabic_stopwords]\n",
    "    \n",
    "    # Apply stemming\n",
    "    tokens = [stemmer.stem(word) for word in tokens]\n",
    "    \n",
    "    return '\\n'.join(tokens)  # Ensure each word appears on a new line\n",
    "\n",
    "# Apply preprocessing\n",
    "df['Processed_Lyrics'] = df['Lyrics'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107\n"
     ]
    }
   ],
   "source": [
    "#print number of rows in the dataset\n",
    "print(df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Lyricist: 107\n",
      "Length of Composer: 107\n",
      "Length of Year: 107\n"
     ]
    }
   ],
   "source": [
    "Lyricist = ['نادر عبدالله', 'محمد رفاعى', 'سلامة على', 'احمد الجندى', 'محمد الرفاعى', 'امير طعيمة', 'ايمن قميحة', 'احمد ماضى', 'امير طعيمة', 'كميل خورى', 'اسماعيل الحبروك', 'نادر عبدالله', 'شادى نور', 'عمر سارى', 'عمر سارى', 'هانى عبد الكريم', 'سهام الشعشاع', 'محمد جمعه', 'سلامه على', 'ايمن بهجت قمر', 'سلامه على', 'مروان خورى', 'الياس ناصر', 'نادر عبدالله', 'فيصل همامى', 'احمد مرزوق', 'روميو لحود', 'احمد الجندى', 'سلامه على', 'نادر عبدالله', 'احمد الجندى', 'امير طعيمه', 'نادر عبدالله', 'عادل رفول', 'مروان سعادة', 'نادر عبدالله', 'سامح العجمى', 'الياس ناصر', 'محمد رحيم', 'كمال القبيسى', 'الياس ناصر', 'مروان خورى', 'ملاك عادل', 'محمد رفاعى', 'الياس ناصر', 'نبيل ابو عبدو', 'نبيل ابو عبدو', 'اسامه مصطفى', 'احمد مرزوق', 'فارس اسكندر', 'سليم عساف', 'محمد رفاعى', 'تامر حسين', 'نادر عبدالله', 'امير طعيمه', 'رامى جمال', 'مروان خورى', 'سهام الشعشاع', 'امير طعيمه', 'احمد الجندى', 'نادر عبدالله', 'احمد مرزوق', 'يوسف سليمان', 'مروان خورى', 'نادر عبدالله', 'محمد رحيم', 'تامر حبيب', 'نادر عبدالله', 'محمد رفاعى', 'اسامه مصطفى', 'عادل رفول', 'مروان خورى', 'على المولى', 'نزار فرنسىس', 'اكرام العاصى', 'طونى ابى كرم', 'نادر عبدالله', 'مروان خورى', 'بهاء الدىن محمد', 'هانى عبد الكرىم', 'منىر بو عساف', 'منىر جورج عساف', 'اسامة مصطفى', 'نادر عبدالله', 'على المولى', 'نادر عبدالله', 'اسامة مصطفى', 'احمد الجندى', 'على المولى', 'بهاء الدىن محمد', 'نادر عبدالله', 'خالد امىن', 'امير طعيمة', 'نادر عبدالله', 'اسامه مصطفى', 'امير طعيمة', 'نادر عبدالله', 'الياس ناصر', 'نادر عبدالله', 'نادر عبدالله', 'شادى نور', 'سعىد مرسى', 'الياس ناصر', 'نادر عبدالله', 'تامر حبيب', 'صلاح الكردي', 'أحمد ماضي']\n",
    "\n",
    "Composer = ['ياسر نور', 'محمد رحيم و محمد رفاعى', 'محمد يحيى', 'مدين', 'ايمن محسب', 'وليد سعد', 'اوسين', 'زياد برجى', 'وليد سعد', 'كميل خورى', 'منير مراد', 'تامر على', 'محمد يحيى', 'محمد بشار', 'محمد بشار', 'وليد سعد', 'محمد رحيم', 'محمد رحيم', 'شريف بدر', 'محمد يحيى', 'محمد يحيى', 'مروان شهود', 'غوليس', 'محمد يحيى', 'تامر على', 'محمد يحيى', 'روميو لحود', 'مدين', 'محمد يحيى', 'سونر جيركيكير', 'مدين', 'زياد برجى', 'تامر عاشور', 'ناصر الاسعد', 'برنار لياميس و جيف بارنيل', 'وليد سعد', 'شريف تاج', 'جورج كرم', 'محمد رحيم', 'اسامه الرحبانى', 'سردار اورتاج', 'مروان خورى', 'محمد يحيى', 'محمد رفاعى', 'الكس فوكس', 'جيرار فيرير', 'تركان', 'سامر ابو طالب', 'محمد رحيم', 'سليم سلامه', 'سليم عساف', 'حسام حبيب و جان مارى رياشى', 'عمرو مصطفى', 'محمد رحيم', 'وليد سعد', 'رامى جمال', 'مروان خورى', 'محمد رحيم', 'محمد يحيى', 'مدين', 'وليد سعد', 'محمد رحيم', 'صلاح الكردى', 'مروان خورى', 'تامر عاشور', 'محمد رحيم', 'ايهاب عبد الواحد', 'محمد يحيى', 'حسام حبيب', 'سامر ابو طالب', 'جان صليبا', 'مروان خورى', 'فضل سليمان', 'ناصر الاسعد', 'محمد رحيم','ناصر الاسعد', 'رامى جمال', 'مروان خورى', 'مدين', 'مدين', 'نهاد نجار', 'نهاد نجار', 'محمد يحيى', 'تامر على', 'صلاح الكردى', 'تامر عاشور', 'سامر ابو طالب', 'مدين', 'رامى الشافعى', 'مدين', 'وليد سعد', 'محمد رحيم', 'رامى جمال', 'محمد يحيى', 'سامر ابو طالب', 'رامى جمال', 'جان صليبا', 'فياز كوروز', 'ابراهيم تاتليسس', 'محمد يحيى', 'محمد يحيى', 'بليغ حمدى', 'فياز كوروز', 'نزيه اسلر', 'ايهاب عبد الواحد', 'صلاح الكردي ','زياد برجي']\n",
    "\n",
    "Year = ['2006', '2002', '2012', '2016', '2008', '2020', '2014', '2022', '2018', '2017', '2014', '2007', '2018', '2020', '2018', '2018', '2012', '2010', '2016', '2023', '2014', '2008', '1999', '2014', '2006', '2014', '2018', '2018', '2012', '2014', '2014', '2020', '2006', '1999', '2015', '2007', '2004', '2000', '2017', '2022', '2000', '2010', '2016', '2005', '2000', '2005', '2002', '2020', '2022', '2009', '2018', '2002', '2018', '2020', '2016', '2020', '2023', '2019', '2014', '2016', '2010', '2012', '2016', '2009', '2006', '2012', '2019', '2014', '2004', '2016', '2012', '2006', '2018', '2002', '2007', '2002', '2018', '2014', '2014', '2012', '2006', '2004', '2020', '2009', '2023', '2012', '2016', '2016', '2018', '2016', '2009', '2012', '2018', '2016', '2016', '2022', '2018', '2000', '2018', '2016', '2020', '2018', '2000', '2016', '2019', '2016', '2014']\n",
    "\n",
    "print(f\"Length of Lyricist: {len(Lyricist)}\")\n",
    "print(f\"Length of Composer: {len(Composer)}\")\n",
    "print(f\"Length of Year: {len(Year)}\")\n",
    "\n",
    "df['Lyricist'] = Lyricist\n",
    "df['composer'] = Composer\n",
    "df['year']= Year\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model and tokenizer\n",
    "model_name = \"CAMeL-Lab/bert-base-arabic-camelbert-mix-sentiment\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment labels mapping (based on CAMeL BERT sentiment analysis)\n",
    "id2label = {0: \"negative\", 1: \"neutral\", 2: \"positive\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bert_sentiment_analysis(lyrics):\n",
    "    if not isinstance(lyrics, str) or lyrics.strip() == '':\n",
    "        return 'neutral'\n",
    "    \n",
    "    # Truncate to 512 tokens (BERT's max length)\n",
    "    lyrics = ' '.join(lyrics.split()[:512])\n",
    "\n",
    "    # Tokenize the input text\n",
    "    inputs = tokenizer(lyrics, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
    "\n",
    "    # Perform inference\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    # Get predicted sentiment\n",
    "    predicted_class = torch.argmax(outputs.logits).item()\n",
    "    return id2label[predicted_class]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply to DataFrame\n",
    "df['Sentiment_BERT'] = df['Lyrics'].apply(bert_sentiment_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT-Based Sentiment Analysis Results:\n",
      "                   Song Title Sentiment_BERT\n",
      "0                   متخفش مني       positive\n",
      "1                  أجمل إحساس       negative\n",
      "2                  أسعد واحدة       negative\n",
      "3             أغلى الحبايب El       negative\n",
      "4  أنا بستغرب عليه Bastaghrab        neutral\n"
     ]
    }
   ],
   "source": [
    "print(\"BERT-Based Sentiment Analysis Results:\")\n",
    "print(df[['Song Title', 'Sentiment_BERT']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = 'C:\\\\Users\\\\Kimo Store\\\\Downloads\\\\deep\\\\output\\\\elissa_lyrics_preprocessed.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the preprocessed lyrics to another csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed lyrics saved to C:\\Users\\Kimo Store\\Downloads\\deep\\output\\elissa_lyrics_preprocessed.csv\n",
      "                   Song Title  \\\n",
      "0                   متخفش مني   \n",
      "1                  أجمل إحساس   \n",
      "2                  أسعد واحدة   \n",
      "3             أغلى الحبايب El   \n",
      "4  أنا بستغرب عليه Bastaghrab   \n",
      "\n",
      "                                              Lyrics  \\\n",
      "0  متخفش مني\\nمتخفش مني\\nمتخفش مني\\nمتخفش مني\\nأن...   \n",
      "1  أجمل إحساس\\nأجمل إحساس\\nأجمل إحساس\\nأجمل إحساس...   \n",
      "2  أسعد واحدة\\nأسعد واحدة\\nأسعد واحدة\\nالفرحة الل...   \n",
      "3  أغلى الحبايب\\nأغلى الحبايب\\nأغلى الحبايب\\nأغلى...   \n",
      "4  أنا بستغرب عليه\\nأنا بستغرب عليه\\nأنا بستغرب ع...   \n",
      "\n",
      "                                                 URL  \\\n",
      "0  https://lyricstranslate.com/en/elissa-metkahaf...   \n",
      "1  https://lyricstranslate.com/en/elissa-agmal-eh...   \n",
      "2  https://lyricstranslate.com/en/elissa-assad-wa...   \n",
      "3  https://lyricstranslate.com/en/elissa-aghla-el...   \n",
      "4  https://lyricstranslate.com/en/elissa-ana-bast...   \n",
      "\n",
      "                                    Processed_Lyrics      Lyricist  \\\n",
      "0  تخفش\\nمنى\\nتخفش\\nمنى\\nتخفش\\nمنى\\nتخفش\\nمنى\\nان...  نادر عبدالله   \n",
      "1  جمل\\nحسس\\nجمل\\nحسس\\nجمل\\nحسس\\nجمل\\nحسس\\nفى\\nكو...    محمد رفاعى   \n",
      "2  سعد\\nوحد\\nسعد\\nوحد\\nسعد\\nوحد\\nفرح\\nالى\\nانا\\nد...     سلامة على   \n",
      "3  غلى\\nحبيب\\nغلى\\nحبيب\\nغلى\\nحبيب\\nغلى\\nحبيب\\nال...   احمد الجندى   \n",
      "4  انا\\nغرب\\nانا\\nغرب\\nانا\\nغرب\\nانا\\nغرب\\nعلی\\nا...  محمد الرفاعى   \n",
      "\n",
      "                 composer  year Sentiment_BERT  \n",
      "0                ياسر نور  2006       positive  \n",
      "1  محمد رحيم و محمد رفاعى  2002       negative  \n",
      "2               محمد يحيى  2012       negative  \n",
      "3                    مدين  2016       negative  \n",
      "4               ايمن محسب  2008        neutral  \n"
     ]
    }
   ],
   "source": [
    "df.to_csv(output_file, index=False, encoding='utf-8-sig')\n",
    "print(f\"Preprocessed lyrics saved to {output_file}\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
